{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d84ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # For making HTTP requests to the API.\n",
    "import time # For adding a delay (so we donâ€™t overload the API).\n",
    "import pandas as pd # For handling tabular data and CSV.\n",
    "import great_expectations as gx # For validating data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7326cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from API...\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data.wa.gov/resource/f6w7-q2d2.json\" # API endpoint for WA EV data.\n",
    "limit = 1000 # Number of rows to fetch per request.\n",
    "offset = 0 # Starting offset for pagination.\n",
    "all_data = [] # Empty list to collect API results.\n",
    "\n",
    "print(\"Fetching data from API...\") # Log progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a610e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1000 records | Total so far: 1000\n",
      "Fetched 1000 records | Total so far: 2000\n",
      "Fetched 1000 records | Total so far: 3000\n",
      "Fetched 1000 records | Total so far: 4000\n",
      "Fetched 1000 records | Total so far: 5000\n",
      "Fetched 1000 records | Total so far: 6000\n",
      "Fetched 1000 records | Total so far: 7000\n",
      "Fetched 1000 records | Total so far: 8000\n",
      "Fetched 1000 records | Total so far: 9000\n",
      "Fetched 1000 records | Total so far: 10000\n",
      "Fetched 1000 records | Total so far: 11000\n",
      "Fetched 1000 records | Total so far: 12000\n",
      "Fetched 1000 records | Total so far: 13000\n",
      "Fetched 1000 records | Total so far: 14000\n",
      "Fetched 1000 records | Total so far: 15000\n",
      "Fetched 1000 records | Total so far: 16000\n",
      "Fetched 1000 records | Total so far: 17000\n",
      "Fetched 1000 records | Total so far: 18000\n",
      "Fetched 1000 records | Total so far: 19000\n",
      "Fetched 1000 records | Total so far: 20000\n",
      "Fetched 1000 records | Total so far: 21000\n",
      "Fetched 1000 records | Total so far: 22000\n",
      "Fetched 1000 records | Total so far: 23000\n",
      "Fetched 1000 records | Total so far: 24000\n",
      "Fetched 1000 records | Total so far: 25000\n",
      "Fetched 1000 records | Total so far: 26000\n",
      "Fetched 1000 records | Total so far: 27000\n",
      "Fetched 1000 records | Total so far: 28000\n",
      "Fetched 1000 records | Total so far: 29000\n",
      "Fetched 1000 records | Total so far: 30000\n",
      "Fetched 1000 records | Total so far: 31000\n",
      "Fetched 1000 records | Total so far: 32000\n",
      "Fetched 1000 records | Total so far: 33000\n",
      "Fetched 1000 records | Total so far: 34000\n",
      "Fetched 1000 records | Total so far: 35000\n",
      "Fetched 1000 records | Total so far: 36000\n",
      "Fetched 1000 records | Total so far: 37000\n",
      "Fetched 1000 records | Total so far: 38000\n",
      "Fetched 1000 records | Total so far: 39000\n",
      "Fetched 1000 records | Total so far: 40000\n",
      "Fetched 1000 records | Total so far: 41000\n",
      "Fetched 1000 records | Total so far: 42000\n",
      "Fetched 1000 records | Total so far: 43000\n",
      "Fetched 1000 records | Total so far: 44000\n",
      "Fetched 1000 records | Total so far: 45000\n",
      "Fetched 1000 records | Total so far: 46000\n",
      "Fetched 1000 records | Total so far: 47000\n",
      "Fetched 1000 records | Total so far: 48000\n",
      "Fetched 1000 records | Total so far: 49000\n",
      "Fetched 1000 records | Total so far: 50000\n",
      "Fetched 1000 records | Total so far: 51000\n",
      "Fetched 1000 records | Total so far: 52000\n",
      "Fetched 1000 records | Total so far: 53000\n",
      "Fetched 1000 records | Total so far: 54000\n",
      "Fetched 1000 records | Total so far: 55000\n",
      "Fetched 1000 records | Total so far: 56000\n",
      "Fetched 1000 records | Total so far: 57000\n",
      "Fetched 1000 records | Total so far: 58000\n",
      "Fetched 1000 records | Total so far: 59000\n",
      "Fetched 1000 records | Total so far: 60000\n",
      "Fetched 1000 records | Total so far: 61000\n",
      "Fetched 1000 records | Total so far: 62000\n",
      "Fetched 1000 records | Total so far: 63000\n",
      "Fetched 1000 records | Total so far: 64000\n",
      "Fetched 1000 records | Total so far: 65000\n",
      "Fetched 1000 records | Total so far: 66000\n",
      "Fetched 1000 records | Total so far: 67000\n",
      "Fetched 1000 records | Total so far: 68000\n",
      "Fetched 1000 records | Total so far: 69000\n",
      "Fetched 1000 records | Total so far: 70000\n",
      "Fetched 1000 records | Total so far: 71000\n",
      "Fetched 1000 records | Total so far: 72000\n",
      "Fetched 1000 records | Total so far: 73000\n",
      "Fetched 1000 records | Total so far: 74000\n",
      "Fetched 1000 records | Total so far: 75000\n",
      "Fetched 1000 records | Total so far: 76000\n",
      "Fetched 1000 records | Total so far: 77000\n",
      "Fetched 1000 records | Total so far: 78000\n",
      "Fetched 1000 records | Total so far: 79000\n",
      "Fetched 1000 records | Total so far: 80000\n",
      "Fetched 1000 records | Total so far: 81000\n",
      "Fetched 1000 records | Total so far: 82000\n",
      "Fetched 1000 records | Total so far: 83000\n",
      "Fetched 1000 records | Total so far: 84000\n",
      "Fetched 1000 records | Total so far: 85000\n",
      "Fetched 1000 records | Total so far: 86000\n",
      "Fetched 1000 records | Total so far: 87000\n",
      "Fetched 1000 records | Total so far: 88000\n",
      "Fetched 1000 records | Total so far: 89000\n",
      "Fetched 1000 records | Total so far: 90000\n",
      "Fetched 1000 records | Total so far: 91000\n",
      "Fetched 1000 records | Total so far: 92000\n",
      "Fetched 1000 records | Total so far: 93000\n",
      "Fetched 1000 records | Total so far: 94000\n",
      "Fetched 1000 records | Total so far: 95000\n",
      "Fetched 1000 records | Total so far: 96000\n",
      "Fetched 1000 records | Total so far: 97000\n",
      "Fetched 1000 records | Total so far: 98000\n",
      "Fetched 1000 records | Total so far: 99000\n",
      "Fetched 1000 records | Total so far: 100000\n",
      "Fetched 1000 records | Total so far: 101000\n",
      "Fetched 1000 records | Total so far: 102000\n",
      "Fetched 1000 records | Total so far: 103000\n",
      "Fetched 1000 records | Total so far: 104000\n",
      "Fetched 1000 records | Total so far: 105000\n",
      "Fetched 1000 records | Total so far: 106000\n",
      "Fetched 1000 records | Total so far: 107000\n",
      "Fetched 1000 records | Total so far: 108000\n",
      "Fetched 1000 records | Total so far: 109000\n",
      "Fetched 1000 records | Total so far: 110000\n",
      "Fetched 1000 records | Total so far: 111000\n",
      "Fetched 1000 records | Total so far: 112000\n",
      "Fetched 1000 records | Total so far: 113000\n",
      "Fetched 1000 records | Total so far: 114000\n",
      "Fetched 1000 records | Total so far: 115000\n",
      "Fetched 1000 records | Total so far: 116000\n",
      "Fetched 1000 records | Total so far: 117000\n",
      "Fetched 1000 records | Total so far: 118000\n",
      "Fetched 1000 records | Total so far: 119000\n",
      "Fetched 1000 records | Total so far: 120000\n",
      "Fetched 1000 records | Total so far: 121000\n",
      "Fetched 1000 records | Total so far: 122000\n",
      "Fetched 1000 records | Total so far: 123000\n",
      "Fetched 1000 records | Total so far: 124000\n",
      "Fetched 1000 records | Total so far: 125000\n",
      "Fetched 1000 records | Total so far: 126000\n",
      "Fetched 1000 records | Total so far: 127000\n",
      "Fetched 1000 records | Total so far: 128000\n",
      "Fetched 1000 records | Total so far: 129000\n",
      "Fetched 1000 records | Total so far: 130000\n",
      "Fetched 1000 records | Total so far: 131000\n",
      "Fetched 1000 records | Total so far: 132000\n",
      "Fetched 1000 records | Total so far: 133000\n",
      "Fetched 1000 records | Total so far: 134000\n",
      "Fetched 1000 records | Total so far: 135000\n",
      "Fetched 1000 records | Total so far: 136000\n",
      "Fetched 1000 records | Total so far: 137000\n",
      "Fetched 1000 records | Total so far: 138000\n",
      "Fetched 1000 records | Total so far: 139000\n",
      "Fetched 1000 records | Total so far: 140000\n",
      "Fetched 1000 records | Total so far: 141000\n",
      "Fetched 1000 records | Total so far: 142000\n",
      "Fetched 1000 records | Total so far: 143000\n",
      "Fetched 1000 records | Total so far: 144000\n",
      "Fetched 1000 records | Total so far: 145000\n",
      "Fetched 1000 records | Total so far: 146000\n",
      "Fetched 1000 records | Total so far: 147000\n",
      "Fetched 1000 records | Total so far: 148000\n",
      "Fetched 1000 records | Total so far: 149000\n",
      "Fetched 1000 records | Total so far: 150000\n",
      "Fetched 1000 records | Total so far: 151000\n",
      "Fetched 1000 records | Total so far: 152000\n",
      "Fetched 1000 records | Total so far: 153000\n",
      "Fetched 1000 records | Total so far: 154000\n",
      "Fetched 1000 records | Total so far: 155000\n",
      "Fetched 1000 records | Total so far: 156000\n",
      "Fetched 1000 records | Total so far: 157000\n",
      "Fetched 1000 records | Total so far: 158000\n",
      "Fetched 1000 records | Total so far: 159000\n",
      "Fetched 1000 records | Total so far: 160000\n",
      "Fetched 1000 records | Total so far: 161000\n",
      "Fetched 1000 records | Total so far: 162000\n",
      "Fetched 1000 records | Total so far: 163000\n",
      "Fetched 1000 records | Total so far: 164000\n",
      "Fetched 1000 records | Total so far: 165000\n",
      "Fetched 1000 records | Total so far: 166000\n",
      "Fetched 1000 records | Total so far: 167000\n",
      "Fetched 1000 records | Total so far: 168000\n",
      "Fetched 1000 records | Total so far: 169000\n",
      "Fetched 1000 records | Total so far: 170000\n",
      "Fetched 1000 records | Total so far: 171000\n",
      "Fetched 1000 records | Total so far: 172000\n",
      "Fetched 1000 records | Total so far: 173000\n",
      "Fetched 1000 records | Total so far: 174000\n",
      "Fetched 1000 records | Total so far: 175000\n",
      "Fetched 1000 records | Total so far: 176000\n",
      "Fetched 1000 records | Total so far: 177000\n",
      "Fetched 1000 records | Total so far: 178000\n",
      "Fetched 1000 records | Total so far: 179000\n",
      "Fetched 1000 records | Total so far: 180000\n",
      "Fetched 1000 records | Total so far: 181000\n",
      "Fetched 1000 records | Total so far: 182000\n",
      "Fetched 1000 records | Total so far: 183000\n",
      "Fetched 1000 records | Total so far: 184000\n",
      "Fetched 1000 records | Total so far: 185000\n",
      "Fetched 1000 records | Total so far: 186000\n",
      "Fetched 1000 records | Total so far: 187000\n",
      "Fetched 1000 records | Total so far: 188000\n",
      "Fetched 1000 records | Total so far: 189000\n",
      "Fetched 1000 records | Total so far: 190000\n",
      "Fetched 1000 records | Total so far: 191000\n",
      "Fetched 1000 records | Total so far: 192000\n",
      "Fetched 1000 records | Total so far: 193000\n",
      "Fetched 1000 records | Total so far: 194000\n",
      "Fetched 1000 records | Total so far: 195000\n",
      "Fetched 1000 records | Total so far: 196000\n",
      "Fetched 1000 records | Total so far: 197000\n",
      "Fetched 1000 records | Total so far: 198000\n",
      "Fetched 1000 records | Total so far: 199000\n",
      "Fetched 1000 records | Total so far: 200000\n",
      "Fetched 1000 records | Total so far: 201000\n",
      "Fetched 1000 records | Total so far: 202000\n",
      "Fetched 1000 records | Total so far: 203000\n",
      "Fetched 1000 records | Total so far: 204000\n",
      "Fetched 1000 records | Total so far: 205000\n",
      "Fetched 1000 records | Total so far: 206000\n",
      "Fetched 1000 records | Total so far: 207000\n",
      "Fetched 1000 records | Total so far: 208000\n",
      "Fetched 1000 records | Total so far: 209000\n",
      "Fetched 1000 records | Total so far: 210000\n",
      "Fetched 1000 records | Total so far: 211000\n",
      "Fetched 1000 records | Total so far: 212000\n",
      "Fetched 1000 records | Total so far: 213000\n",
      "Fetched 1000 records | Total so far: 214000\n",
      "Fetched 1000 records | Total so far: 215000\n",
      "Fetched 1000 records | Total so far: 216000\n",
      "Fetched 1000 records | Total so far: 217000\n",
      "Fetched 1000 records | Total so far: 218000\n",
      "Fetched 1000 records | Total so far: 219000\n",
      "Fetched 1000 records | Total so far: 220000\n",
      "Fetched 1000 records | Total so far: 221000\n",
      "Fetched 1000 records | Total so far: 222000\n",
      "Fetched 1000 records | Total so far: 223000\n",
      "Fetched 1000 records | Total so far: 224000\n",
      "Fetched 1000 records | Total so far: 225000\n",
      "Fetched 1000 records | Total so far: 226000\n",
      "Fetched 1000 records | Total so far: 227000\n",
      "Fetched 1000 records | Total so far: 228000\n",
      "Fetched 1000 records | Total so far: 229000\n",
      "Fetched 1000 records | Total so far: 230000\n",
      "Fetched 1000 records | Total so far: 231000\n",
      "Fetched 1000 records | Total so far: 232000\n",
      "Fetched 1000 records | Total so far: 233000\n",
      "Fetched 1000 records | Total so far: 234000\n",
      "Fetched 1000 records | Total so far: 235000\n",
      "Fetched 1000 records | Total so far: 236000\n",
      "Fetched 1000 records | Total so far: 237000\n",
      "Fetched 1000 records | Total so far: 238000\n",
      "Fetched 1000 records | Total so far: 239000\n",
      "Fetched 1000 records | Total so far: 240000\n",
      "Fetched 1000 records | Total so far: 241000\n",
      "Fetched 1000 records | Total so far: 242000\n",
      "Fetched 1000 records | Total so far: 243000\n",
      "Fetched 1000 records | Total so far: 244000\n",
      "Fetched 1000 records | Total so far: 245000\n",
      "Fetched 1000 records | Total so far: 246000\n",
      "Fetched 1000 records | Total so far: 247000\n",
      "Fetched 1000 records | Total so far: 248000\n",
      "Fetched 1000 records | Total so far: 249000\n",
      "Fetched 1000 records | Total so far: 250000\n",
      "Fetched 1000 records | Total so far: 251000\n",
      "Fetched 1000 records | Total so far: 252000\n",
      "Fetched 1000 records | Total so far: 253000\n",
      "Fetched 1000 records | Total so far: 254000\n",
      "Fetched 1000 records | Total so far: 255000\n",
      "Fetched 1000 records | Total so far: 256000\n",
      "Fetched 1000 records | Total so far: 257000\n",
      "Fetched 635 records | Total so far: 257635\n",
      "Total records fetched: 257635\n"
     ]
    }
   ],
   "source": [
    "while True: # Loop until no more data.\n",
    "    url = f\"{base_url}?$limit={limit}&$offset={offset}\" # Build paginated URL.\n",
    "    response = requests.get(url) # Send GET request.\n",
    "\n",
    "    if response.status_code != 200: # If request fails.\n",
    "        print(f\"Error fetching data: {response.status_code}\") # Print error.\n",
    "        break # Exit loop.\n",
    "\n",
    "    batch = response.json() # Parse JSON response.\n",
    "    if not batch: # Stop if no data.\n",
    "        break\n",
    "\n",
    "    all_data.extend(batch) # Append batch into list.\n",
    "    offset += limit # Increase offset for next page.\n",
    "\n",
    "    print(f\"Fetched {len(batch)} records | Total so far: {len(all_data)}\") # progress log.\n",
    "\n",
    "    time.sleep(1) # Delay to respect API limits.\n",
    "\n",
    "print(f\"Total records fetched: {len(all_data)}\") # Final count after loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad38839",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'D:\\Ardi Kurniawan Kusuma\\HACKTIV8\\CODA_RMT_008\\PHASE 2\\WEEK 4\final-project-coda-008-rmt-group-1\\Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m csv_file = \u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mArdi Kurniawan Kusuma\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mHACKTIV8\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCODA_RMT_008\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mPHASE 2\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWEEK 4\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[33minal-project-coda-008-rmt-group-1\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mData\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mev_population_data_raw.csv\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# File name for saving CSV.\u001b[39;00m\n\u001b[32m      2\u001b[39m df = pd.DataFrame(all_data) \u001b[38;5;66;03m# Convert list â†’ DataFrame.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df.to_csv(csv_file, index=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Save DataFrame as CSV.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\gxenv\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3891\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3893\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3894\u001b[39m     frame=df,\n\u001b[32m   3895\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3899\u001b[39m     decimal=decimal,\n\u001b[32m   3900\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3902\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter).to_csv(\n\u001b[32m   3903\u001b[39m     path_or_buf,\n\u001b[32m   3904\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   3905\u001b[39m     sep=sep,\n\u001b[32m   3906\u001b[39m     encoding=encoding,\n\u001b[32m   3907\u001b[39m     errors=errors,\n\u001b[32m   3908\u001b[39m     compression=compression,\n\u001b[32m   3909\u001b[39m     quoting=quoting,\n\u001b[32m   3910\u001b[39m     columns=columns,\n\u001b[32m   3911\u001b[39m     index_label=index_label,\n\u001b[32m   3912\u001b[39m     mode=mode,\n\u001b[32m   3913\u001b[39m     chunksize=chunksize,\n\u001b[32m   3914\u001b[39m     quotechar=quotechar,\n\u001b[32m   3915\u001b[39m     date_format=date_format,\n\u001b[32m   3916\u001b[39m     doublequote=doublequote,\n\u001b[32m   3917\u001b[39m     escapechar=escapechar,\n\u001b[32m   3918\u001b[39m     storage_options=storage_options,\n\u001b[32m   3919\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\gxenv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m   1131\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1133\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m   1134\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m   1135\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1150\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1151\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m csv_formatter.save()\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1155\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\gxenv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    249\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m    250\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.encoding,\n\u001b[32m    251\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.errors,\n\u001b[32m    252\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.compression,\n\u001b[32m    253\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.storage_options,\n\u001b[32m    254\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    257\u001b[39m         handles.handle,\n\u001b[32m    258\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    263\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    264\u001b[39m     )\n\u001b[32m    266\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\gxenv\\Lib\\site-packages\\pandas\\io\\common.py:739\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    743\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\gxenv\\Lib\\site-packages\\pandas\\io\\common.py:604\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    602\u001b[39m parent = Path(path).parent\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'D:\\Ardi Kurniawan Kusuma\\HACKTIV8\\CODA_RMT_008\\PHASE 2\\WEEK 4\final-project-coda-008-rmt-group-1\\Data'"
     ]
    }
   ],
   "source": [
    "csv_file = \"D:\\Ardi Kurniawan Kusuma\\HACKTIV8\\CODA_RMT_008\\PHASE 2\\WEEK 4\\final-project-coda-008-rmt-group-1\\Data\\ev_population_data_raw.csv\" # File name for saving CSV.\n",
    "df = pd.DataFrame(all_data) # Convert list â†’ DataFrame.\n",
    "df.to_csv(csv_file, index=False) # Save DataFrame as CSV.\n",
    "print(f\"Data saved to {csv_file}\") # Confirm save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reloaded = pd.read_csv(csv_file) # Reload CSV into DataFrame.\n",
    "print(\"CSV Reloaded. Shape:\", df_reloaded.shape) # Show shape of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas DataFrame to a Great Expectations Dataset for validation.\n",
    "# Create context.\n",
    "context = FileDataContext.create(project_root_dir='./')\n",
    "\n",
    "# Name Datasource.\n",
    "datasource_name = 'ev_population_data_raw'\n",
    "\n",
    "# Add function to manually overwrite datasource.\n",
    "context.sources.delete(datasource_name)\n",
    "\n",
    "# Create datasource.\n",
    "datasource = context.sources.add_pandas(datasource_name)\n",
    "\n",
    "# Name Data Asset.\n",
    "asset_name = 'ev_population_data'\n",
    "\n",
    "# File path for data validation.\n",
    "path_to_data = './Data/ev_population_data_cleaned.csv'\n",
    "\n",
    "# Create asset.\n",
    "asset = datasource.add_csv_asset(asset_name, filepath_or_buffer=path_to_data)\n",
    "\n",
    "# Create batch request.\n",
    "batch_request = asset.build_batch_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fa6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an expectation suite (a collection of expectations).\n",
    "# Name expectation suite.\n",
    "expectation_suite_name = \"ev_population_suite\"\n",
    "\n",
    "# Create expectation suite.\n",
    "context.add_or_update_expectation_suite(expectation_suite_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validator using above expectation suite.\n",
    "validator = context.get_validator(\n",
    "    batch_request = batch_request,\n",
    "    expectation_suite_name = expectation_suite_name\n",
    ")\n",
    "\n",
    "# Check the validator.\n",
    "validator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation 1: Booking ID should be unique.\n",
    "validator.expect_column_values_to_be_unique(column=\"Booking ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation 2: Ride Distance should be between a min_value and max_value.\n",
    "validator.expect_column_values_to_be_between(column=\"Ride Distance\", min_value=0, max_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e266df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation 3: Vehicle Type should be in a specific set of allowed values.\n",
    "validator.expect_column_values_to_be_in_set(\n",
    "    column=\"Vehicle Type\",\n",
    "    value_set=[\"Go Mini\", \"Go Sedan\", \"Auto\", \"eBike\", \"Bike\", \"Uber XL\", \"Premier Sedan\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all expectations defined on the validator.\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Print the validation results.\n",
    "print(validation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
